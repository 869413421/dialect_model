{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 使用聊天模型和提示模板构建一个简单的 LLM 应用程序",
   "id": "41819353cc320467"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "在本快速入门中，我们将向您展示如何使用 LangChain 构建一个简单的 LLM 应用程序。此应用程序会将文本从英语翻译成另一种语言。这是一个相对简单的 LLM 应用程序 - 它只是一个 LLM 调用加上一些提示。尽管如此，这仍然是开始使用 LangChain 的好方法 - 只需一些提示和 LLM！",
   "id": "cd9005e7504302d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 安装Langchain",
   "id": "586f2c90bb537020"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "! pip install langchain==0.3.9",
   "id": "a6c065a2ef633254",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 加载环境变量",
   "id": "dc15c43800bf3418"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 读取本地/项目的环境变量。\n",
    "# find_dotenv()寻找并定位.env文件的路径\n",
    "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中  \n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "env = load_dotenv(find_dotenv())"
   ],
   "id": "6e22e472ccfbdc89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LangSmith",
   "id": "ebc55ce78f1cd766"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "您使用 LangChain 构建的许多应用程序将包含多个步骤，其中包含多次调用 LLM 调用。随着这些应用程序变得越来越复杂，能够检查您的链条或代理内部到底发生了什么变得至关重要。最好的方法是使用 LangSmith。",
   "id": "7ff5576a7aea78c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#　这是langchain提供的一种调用的追踪平台，能看到调用链路的输入和输出\n",
    "import os\n",
    "\n",
    "print(os.environ[\"LANGCHAIN_TRACING_V2\"]) \n",
    "print(os.environ[\"LANGCHAIN_API_KEY\"])"
   ],
   "id": "b66fe8402d6d3a19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 创建语言模型",
   "id": "5dc7d6f9aced8290"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install -qU langchain-openai",
   "id": "8876120aeb07a5f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "base_url = os.environ[\"BASE_URL\"]\n",
    "api_key = os.environ[\"API_KEY\"]\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", api_key=api_key, base_url=base_url)"
   ],
   "id": "b027f82aee1db952",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们首先直接使用模型。ChatModel 是 LangChain Runnables 的实例，这意味着它们公开了用于与它们交互的标准接口。要简单地调用模型，我们可以将消息列表传递给 .invoke 方法。",
   "id": "325cbeb5c0144b76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"将以下内容从中文翻译成英文\"),\n",
    "    HumanMessage(\"你好吗？\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ],
   "id": "5df39c9ecb59d239",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 流式输出\n",
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ],
   "id": "b6b9b63d332c025f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 提示模板",
   "id": "42fda254369c77ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "现在，我们将消息列表直接传递到语言模型中。此消息列表来自何处？通常，它是由用户输入和应用程序逻辑的组合构建的。此应用程序逻辑通常采用原始用户输入，并将其转换为准备传递给语言模型的消息列表。常见转换包括添加系统消息或使用用户输入设置模板格式。",
   "id": "83b96fedc319dcfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "提示模板是 LangChain 中的一个概念，旨在协助进行这种转换。它们接收原始用户输入并返回准备传递到语言模型的数据（提示）。",
   "id": "fb7a95a029edde91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "language：要将文本翻译成的语言",
   "id": "f543fd01e83aaab3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "text： 要翻译的文本",
   "id": "aa163761b8e2e5e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"将以下内容从 中文 翻译成  {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ],
   "id": "6f4978624609a72a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt = prompt_template.invoke({\"language\":\"英语\",\"text\":\"你好吗？\"})\n",
    "prompt.to_messages()"
   ],
   "id": "72c9fc28ac86b330",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ],
   "id": "f01ddb71d6c6d2b1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
